<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
    <head>
    <meta name="google-site-verification" content="eoPCGBBxDIK0Ff9Dk_dXsuHMTNzzSEZMbsfO4zriBK8" />
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <link rel="shortcut icon" href="./images/doge.ico">
	<meta name="keywords" content="Â∏∏Ëø™, Chang Di, Â∏∏Ëø™, CHANG Di, Â∏∏Ëø™, Di CHANG, University of Southern California, USC, Technical University of Munich, TUMÔºåDalian University of TechnologyÔºåDLUT, DUT, Â§ßËøûÁêÜÂ∑•Â§ßÂ≠¶, ÊÖïÂ∞ºÈªëÂ∑•‰∏öÂ§ßÂ≠¶, ÂçóÂä†Â∑ûÂ§ßÂ≠¶, M√ºnchen, Munich, ÊÖïÂ∞ºÈªë, California, Âä†Âà©Á¶èÂ∞º‰∫öÂ∑û">
	<meta name="description" content="Di CHANG&#39;s Home Page">
<!--    <link href="main.css" media="all" rel="stylesheet">-->
    <link rel="stylesheet" href="jemdoc.css" type="text/css">
    <title>Di CHANG | Â∏∏Ëø™</title>
    </head>

<body>


<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">
					<h1 style="color:#FF0000">Di (Kilian) Chang</h1><h1>
					<h1 style="color:#FF0000">Â∏∏Ëø™</h1><h1>
				</h1></div>

				<h3>CS Ph.D.  @ <a href="https://www.usc.edu/" target="_blank">University of Southern California</a></h3>
				<!-- <h3>Research Scientist Intern @ <a href="https://www.tiktok.com/en/" target="_blank">TikTok</a></h3> -->
<!--                <h3>University of Southern California</h3>-->
				<p>
					<a href="https://www.cs.usc.edu/" target="_blank">Department of Computer Science</a> <br>
					<a href="https://viterbischool.usc.edu/" target="_blank">Viterbi School of Engineering</a><br>
					<a href="https://www.usc.edu/" target="_blank">University of Southern California</a> <br>

<!--					Rm B06, Hedco Neurosciences Building, 3641 Watt Way, Los Angeles, CA 90089-2520, USA <br>-->

					Email1: dichang at usc dot edu (primary) <br>
					Email2: dchang at ict dot usc dot edu <br>
					Email3: di dot chang at bytedance dot com
				</p>
				<p> <a href="https://scholar.google.com.hk/citations?hl=en&user=68wkMTgAAAAJ" target="_blank"><img src="./pics/google_scholar3.png" height="40px" style="margin-bottom:-3px"></a>
					<a href="https://github.com/Boese0601" target="_blank"><img src="./pics/github_s.jpg" height="40px" style="margin-bottom:-3px"></a>
					<a href="https://twitter.com/DiChang10" target="_blank"><img src="./images/twitter.png" height="40px" style="margin-bottom:-3px"></a>
					<a href="https://www.instagram.com/kiliandi10/" target="_blank"><img src="./files/ins.png" height="40px" style="margin-bottom:-3px"></a>
                    <a href="https://www.linkedin.com/in/di-chang-004784206/" target="_blank"><img src="./pics/LinkedIn2.png" height="40px" style="margin-bottom:-3px"></a>
                    <a href="files/CV_Di.pdf"><img src="./pics/cv2.png" height="40px" style="margin-bottom:-3px"></a>
					&nbsp &nbsp
					<!-- <a href="#C1">[<font <font size="3" color="#CB4335"><b>About Me</b></font>] </a> -->
					<a href="#C2">[<font size="3" color="#CB4335"><b>News</b></font>]</a>
					<a href="#edu">[<font size="3" color="#CB4335"><b>Education</b></font>]</a>
					<a href="#C3">[<font size="3" color="#CB4335"><b>Publications</b></font>]</a>
					<a href="#C4">[<font size="3" color="#CB4335"><b>Experience</b></font>]</a></li>
				</p>
			</td>
			<td>
				<img src="./images/dichang.png" border="0" width="230"><br>
<!--				<img src="pics/cover.png" border="0" width="540"><br>-->
			</td>
		</tr><tr>
	</tr></tbody>
</table>

<!--<style>-->
<!--ul-->
<!--{-->
<!--	list-style-type:none;-->
<!--	margin:0;-->
<!--	padding:0;-->
<!--}-->
<!--li a:hover {-->
<!--    background-color: #555;-->
<!--    color: white;-->
<!--}-->

<!--</style>-->


<!--   #0F73B6-->

<h2><a id="C1" ><font color="#CB4335">About Me</font></a></h2>
<p> <a href="https://www.cs.usc.edu/"><img src="./pics/USC_logo.png" height="100px" style="margin-bottom:-3px"></a>&nbsp &nbsp &nbsp
	<a href="https://www.tiktok.com/en/"><img src="./images/TikTok.jpeg" height="100px" style="margin-bottom:-3px"></a>&nbsp &nbsp &nbsp
	<a href="https://www.tum.de/en/"><img src="./images/TUM.jpg" height="100px" style="margin-bottom:-3px"></a>&nbsp &nbsp &nbsp
	<a href="https://www.epfl.ch/en/"><img src="./images/EPFL.png" height="120px" style="margin-bottom:-3px"></a>&nbsp &nbsp &nbsp &nbsp
	<a href="https://hkust.edu.hk/home"><img src="./images/HKUST.jpg" height="100px" style="margin-bottom:-3px"></a>&nbsp &nbsp &nbsp
	<br>
	<br>
	<!-- <a href="https://www.microsoft.com/en-us/research/"><img src="./pics/microsoft_logo.jfif" height="95px" style="margin-bottom:-3px"></a>&nbsp &nbsp &nbsp &nbsp
	<a href="https://www.uii-ai.com/en/"><img src="./pics/UII_logo33.png" height="98px" style="margin-bottom:-3px"></a>&nbsp &nbsp &nbsp
	<a href="http://flexiv.com/"><img src="./pics/flexiv_logo.jfif" height="105px" style="margin-bottom:-3px"></a> -->

</p>
<!-- <p>
	<b>I'm currently looking for research intern working on GenAI/3D Rendering/Human Image & Video Editing/Diffusion Model during 2024 summer. If you have any openings or opportunities to refer, please don't hesitate to contact me!</b>
</p> -->
<p>I am a <strike>first-year</strike> second-year Ph.D. student in the Department of Computer Science at <a  href="https://www.cs.usc.edu/">University of Southern California</a> (USC) with Prof. <a  target="_blank" href=https://people.ict.usc.edu/~soleymani/ target="_blank" rel="external">Mohammad Soleymani</a> of <a  href="https://www.ihp-lab.org/">IHP-Lab</a>.
	I was a Research Scientist Intern at TikTok-ByteDance AI Lab US, Intelligent Creation Team, working with Dr. <a  target="_blank" href=https://seasonsh.github.io/ rel="external"> Yichun Shi </a> and Dr. <a target="_blank" href= https://scholar.google.com/citations?user=_MAKSLkAAAAJ&hl=en  rel="external">Xiao Yang</a> during 2023 summer.
	<!-- I work closely with Prof. <a  target="_blank" href=https://xiaolonw.github.io/ target="_blank" rel="external"> Xiaolong Wang </a> from <a  target="_blank" href=https://ucsd.edu/ target="_blank" rel="external"> UC San Diego </a>. -->
</p>
	Before that, I spent four wonderful years during my undergraduate at <a href="https://en.dlut.edu.cn/">Dalian University of Technology</a> and <a href=https://www.tum.de/en/ target="_blank" >Technical University of Munich</a>, studying Informatics and Information Engineering.
	I'm honored to be advised by Prof. <a  target="_blank" href=https://www.niessnerlab.org/members/matthias_niessner/profile.html target="_blank" rel="external"> Matthias Niessner </a> and
	Dr. <a  target="_blank" href=https://aljazbozic.github.io/ target="_blank" rel="external"> Alja≈æ Bo≈æiƒç </a> during my praktikum at <a  target="_blank" href="https://www.niessnerlab.org/" target="_blank" rel="external">Visual Computing Group</a>.
	I spent a wonderful summer in 2022 with Dr. <a  target="_blank" href=https://sites.google.com/view/tong-zhang rel="external"> Tong Zhang </a>
	and Prof. <a  target="_blank" href=https://people.epfl.ch/sabine.susstrunk?lang=en target="_blank" rel="external"> Sabine S√ºsstrunk</a> at EPFL CS and in 2021 with Prof. <a  target="_blank" href=https://www.danxurgb.net/index.html target="_blank" rel="external"> Dan Xu </a> at HKUST CSE.
</p>
	I'm interested in Computer vision, Multi-View Stereo and Neural Rendering. My current research focuses include:
<ul>
	  <li>3D Vision, especially Multi-View Geometry and Scene Reconstruction with Deep Learning approaches. </li>
	  <li>Video Generation and View Synthesis with Generative Models(DDPM).</li>
	  <li>Multimodal Machine Learning.</li>
	  <li>Facial Expression Analysis and Affective Computing.</li>
<!--	  <li>Effortless AI (how generative models reduce human effort and boost discriminative models)</li>-->
	</ul>
<!--<ul>-->
<!--	  <li>Causal Explainable AI ((1) Understanding reasoning logic and causality of Neural Networks (NN) (2) Use explanation as feedback to help improve the performance of the original NN.) </li>-->
<!--	  <li>Interpretable human-AI interaction (understanding AI models beyond accuracy, such as disentangled representation learning, human-NN knowledge exchange, steerability, generalization, fairness and bias)</li>-->
<!--	  <li>Humanoid Neural Network (simulating human cognitive learning ability (Imagination, Reasoning, Visual Recognition) by using various learning algorithms (Generative models, Representation Learning, Graph Neural Network, Contrastive Learning, etc.)</li>-->
<!--	  <li>Effortless AI (how generative models reduce human effort and boost discriminative models)</li>-->
<!--	</ul>-->

<!--	I'm interested in Machine Learning, Computer vision, and their applications towards Artificial General Intelligence (AGI). My current research focuses include:-->
<!--<ul>-->
<!--	  <li>interpretable human-AI interaction (interpretability, steerability, disentangled representation learning)</li>-->
<!--	  <li>generative models (data augmentation, how generative models boost discriminative models)</li>-->
<!--	  <li>graph neural networks (structure and relationship learning)</li>-->
<!--	  <li>visual reasoning, attention and saliency (cognitive learning, eye tracking)</li>-->
<!--	</ul>-->
<!--<p>My research interests lie in Machine Learning, Computer vision, and AGI. Currently, I am focusing on simulating Cognitive Baby Learning (Imagination, Reasoning, Attention)-->
<!--by using various learning algorithms (Representation Learning, Generative models, GNN, Reinforcement Learning,  Meta-Learning, etc.).</p>-->
<p> <b>Research opportunities</b>:<br>
	For USC undergraduate students: We have openings for interns through <a href=https://viterbiundergrad.usc.edu/research/curve/ target=_blank rel=noopener>CURVE</a> program. Usually we recruit students (first-time researchers and continuing researchers) during Fall and Spring semesters, please apply early. <br><br>
	For USC master students: Please directly email Prof. <a  target="_blank" href=https://people.ict.usc.edu/~soleymani/ target="_blank" rel="external">Mohammad Soleymani</a> for such inquiries. It would be better if you've attended CSCI 535 and obtained a good grade. <br><br>
	For all other students outside USC: we usually don't have openings during Fall and Spring semesters, but Prof. <a  target="_blank" href=https://people.ict.usc.edu/~soleymani/ target="_blank" rel="external">Mohammad Soleymani</a> sometimes recruits good candidates (Undergrad/Ms/visiting PhD) during the Summer. Email him for further details. <br><br>
	I am happy to collaborate and/or answer questions about my research and my previous study at TUM and current PhD program at USC. If you are interested in research collaboration or have any inquiries about my experience, please send me an email.
</p>





<h2><a id="C2" ><font color="#CB4335">News</font></a></h2>
<ul>

<div style="height:200px;width:fit-content;overflow:auto;background:#FFFFFF;">
	<li>
		<p>[2024/02/26] Our <a href=https://freedomgu.github.io/DiffPortrait3D/ rel=noopener>DiffPortrait3D</a> has been accepted by CVPR 2024! See you in Seattle!</p>
	</li>
	<li>
		<p>[2023/08/14] Our <a href=https://boese0601.github.io/fgnet/ target=_blank rel=noopener>FG-Net</a> and <a href=https://boese0601.github.io/fgnet/ target=_blank rel=noopener>LibreFace</a> has been accepted by WACV 2024! Find me at Waikoloa, Hawaii.</p>
	</li>
	<li>
		<p>[2023/05/22]  Start my Summer Internship at <a href="https://www.tiktok.com/en/">TikTok</a> (San Jose Office in CA). Looking forward to building connections with talents in the Bay Area! </p>
	</li>
	<li>
		<p>[2022/08/19]  Today I start my Ph.D. at <a href="https://www.cs.usc.edu/">USC Viterbi Computer Science</a>! Fight on, Trojans!  </p>
	</li>
	<li>
		<p>[2022/07/04]  My first single-first-author paper <a href=https://www.niessnerlab.org/projects/chang2022rcmvsnet.html target=_blank rel=noopener>RC-MVSNet</a> has been accepted by ECCV 2022! See you in Tel Aviv!</p>
	</li>
	<li>
		<p>[2022/04/08]  I'm joining <a href=https://www.ihp-lab.org/ target=_blank rel=noopener>IHP-Lab</a> at <a href=https://www.cs.usc.edu/ target=_blank rel=noopener>USC</a> as a PhD student, see you in Los Angeles!</p>
	</li>
	<li>
		<p>[2022/03/15] Our <a href=https://mizhenxing.github.io/gbinet/ target=_blank rel=noopener>GBi-Net</a> has been accepted by CVPR 2022!</p>
	<li>
		<p>[2022/03/07] I will join <a href=https://www.3dunderstanding.org target=_blank rel=noopener>3D AI Lab</a> at <a href=https://www.tum.de/en/ target=_blank rel=noopener>Technische Universit√§t M√ºnchen</a> as a guided research student with Professor Angela Dai.</p>
	</li>
	<li>
		<p>[2022/01/15] I will join <a href=https://www.epfl.ch/labs/ivrl/ target=_blank rel=noopener>Image and Visual Representation Lab</a> at <a href=https://www.epfl.ch/en/ target=_blank rel=noopener>√âcole Polytechnique F√©d√©rale de Lausanne</a> as a research intern/visiting researcher.
	</li>
	<li>
		<p>[2021/10/15] I will join <a href=https://niessnerlab.org/ target=_blank rel=noopener>Visual Computing & Artificial Intelligence Lab</a> at <a href=https://www.tum.de/en/ target=_blank rel=noopener>Technische Universit√§t M√ºnchen</a> with Professor Matthias Niessner.
	</li>
	<li>
		<p>[2021/03/04] I will join <a href=https://www.danxurgb.net/index.html target=_blank rel=noopener>Prof.Xu&rsquo;s vision group</a> at <a href=https://hkust.edu.hk/home target=_blank rel=noopener>HKUST</a> as a research intern during summer 2021.
	</li>
	

</div>
</ul>
<br>



<h2><a id="edu" ><font color="#CB4335">Education</font></a></h2>
<table>
	<tbody>
		<tr>
			<td width="800">
 
			<h4> University of Southern California, Los Angeles, USA <br>(Aug. 2022 - Present)</h4>
			<ul>
				<li>
				<b>Doctor of Philosophy in Computer Science</b></li>
				<li>Major Orientation: Deep Learning for 3D Vision and Affective Computing </li>
			</ul>
			</td>
<td>
	<img id="school_logo" src="./images/usc_cs_logo.jpeg" height="100px">
</td>
</tr>
<tr></tr>
</tbody></table>



<table>
	<tbody>
		<tr>
			<td width="800">
 
 <h4> Technical University of Munich, Munich, Germany (Aug. 2021 - Jul. 2022)</h4>
 <ul>
	<li>
	  <b>Bachelor of Science in Informatics</b></li>
	<li>Major Orientation: Deep Learning for 3D Perception, 3D Scanning and Spatial Learning </li>
	<li>Overall GPA: 1.2/1.0 </li>
	<li>Bachelor thesis: "Supervised and Unsupervised Multi View Stereo for Depth Inference"</li>
 </ul>
</td>
<td>
	<img id="school_logo" src="./images/TUM.jpg" height="100px">
</td>
</tr>
<tr></tr>
</tbody></table>

<table>
<tbody>
	<tr>
		<td width="800">
 <h4> Dalian University of Technology, Dalian, China (Sep. 2018 - Jul. 2021)</h4>
 <ul>
	<li>
	  <b>Bachelor of Engineering in Eletronic Information Engineering</b></li>
	<li>Major Orientation: Object Detection and Tracking</li>
	<li>Overall GPA: 91.5/100 | 3.93/4.0</li>
 </ul>
</td>
<td>
	<img id="school_logo" src="./images/DUT.jpg" height="100px">
</td>
</tr>
<tr></tr>
</tbody></table>

<h2><a id="C3" ><font color="#CB4335">Preprints</font></a></h2>

<table id="tbPreprints" width="100%">


    <tr>
		<td width="306">
		<img src="images/DIM.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>DIM: Dyadic Interaction Modeling for Social Behavior Generation</b> <br>
			<br>
			<b>Di Chang*</b>, <a href="https://scholar.google.com/citations?hl=en&user=HuuQRj4AAAAJ">Minh Tran*</a>, <a href="https://scholar.google.com/citations?hl=en&user=5w0f0OQAAAAJ">Maksim Siniukov</a>, <a href="https://www.ihp-lab.org/">Mohammad Soleymani</a><br>
			(*equal contribution)<br>
		<em>Arxiv Preprint</em>
		<p></p>
		<p>
			<!-- [<a href="https://boese0601.github.io/magicdance/" target="_blank">project page</a>] -->
			[<a href="" target="_blank">paper</a>]
			<!-- [<a href="https://github.com/Boese0601/MagicDance" target="_blank">code</a>] -->
			<!-- [<a href="https://www.youtube.com/watch?v=VPJe6TyrT-Y" target="_blank">video</a>] -->
		</p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>

	<tr>
		<td width="306">
		<img src="images/magicdance.gif" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>MagicDance: Realistic Human Dance Video Generation with Motions & Facial Expressions Transfer</b> <br>
			<br>
			<b>Di Chang</b>, <a href="https://seasonsh.github.io/">Yichun Shi</a>, <a href="https://zerg-overmind.github.io/">Quankai Gao</a>, <a href="https://www.linkedin.com/in/jessica-fu-60a504254/">Jessica Fu</a>, <a href="https://hongyixu37.github.io/homepage/">Hongyi Xu</a>, <a href="https://guoxiansong.github.io/homepage/index.html">Guoxian Song</a>, <a href="https://scholar.google.com/citations?user=0TIYjPAAAAAJ&hl=en">Qing Yan</a>, <a href="https://scholar.google.com/citations?user=_MAKSLkAAAAJ&hl=en">Xiao Yang</a>, <a href="https://www.ihp-lab.org/">Mohammad Soleymani</a><br>
		<em>Arxiv Preprint</em>
		<p></p>
		<p>
			[<a href="https://boese0601.github.io/magicdance/" target="_blank">project page</a>]
			[<a href="https://arxiv.org/abs/2311.12052" target="_blank">paper</a>]
			[<a href="https://github.com/Boese0601/MagicDance" target="_blank">code</a>]
			[<a href="https://www.youtube.com/watch?v=VPJe6TyrT-Y" target="_blank">video</a>]
		</p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>
   

</table>
<br>


<h2><a id="C3" ><font color="#CB4335">Selected Publications</font></a> [<a href=https://scholar.google.com.hk/citations?hl=en&user=68wkMTgAAAAJ>Google Scholar</a>]</h2>

<table id="tbPublications" width="100%">

	<tr>
		<td width="306">
		<img src="images/diffportrait3d.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>DiffPortrait3D: Controllable Diffusion for Zero-Shot Portrait View Synthesis</b> <br>
			<br>
				<a href="https://yuming-gu.com/">Yuming Gu</a>,
				  <a href="https://ge.in.tum.de/about/you-xie/">Xie You</a>,
				<a href="http://www-scf.usc.edu/~hongyixu/">Hongyi Xu</a>,
				<a href="https://guoxiansong.github.io/homepage/index.html">Guoxian Song</a>,

				  <a href="https://seasonsh.github.io/">Yichun Shi</a>,

				<b>Di Chang</b>,

				  <a href="https://jingyangcarl.com">Jing Yang</a>,

				<a href="http://linjieluo.com/">Linjie Luo</a><br>

				<em>IEEE/ CVF International Conference on Computer Vision and Pattern Recognition</em> (<i><b>CVPR</b></i>), 2024.
		<p></p>
		<p>
			[<a href="https://freedomgu.github.io/DiffPortrait3D/" target="_blank">project page</a>]
			[<a href="https://arxiv.org/abs/2312.13016" target="_blank">paper</a>]
			[<a href="https://github.com/FreedomGu/DiffPortrait3D/" target="_blank">code</a>]
			[<a href="https://www.youtube.com/watch?v=mI8RJ_f3Csw" target="_blank">video</a>]
		</p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>

    <tr>
		<td width="306">
		<img src="images/libre.jpg" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>LibreFace: An Open-Source Toolkit for Deep Facial Expression Analysis</b> <br>
			<br>
			<b>Di Chang</b>, <a href=https://yufengyin.github.io/ target=_blank rel=noopener>Yufeng Yin</a>, Zongjian Li, <a href="https://scholar.google.com/citations?user=HuuQRj4AAAAJ&hl=en" target=_blank rel=noopener>Minh Tran</a>, and <a href=https://people.ict.usc.edu/~soleymani/ target=_blank rel=noopener>Mohammad Soleymani</a><br>
		<em>IEEE/CVF Winter Conference on Applications of Computer Vision</em> (<i><b>WACV</b></i>), 2024.  <b>(Application Track)</b>
		<p></p>
		<p>
			[<a href="https://boese0601.github.io/libreface/" target="_blank">project page</a>]
			[<a href="https://arxiv.org/abs/2308.10713" target="_blank">paper</a>]
			[<a href="https://github.com/ihp-lab/LibreFace" target="_blank">code</a>]
			[<a href="" target="_blank">video</a>]
		</p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>

    <tr>
		<td width="306">
		<img src="images/fgnet.jpg" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>FG-Net: Facial Action Unit Detection with Generalizable Pyramidal Features</b> <br>
			<br>
			<a href="https://yufengyin.github.io/" target=_blank rel=noopener>Yufeng Yin</a>, <b>Di Chang</b>,  <a href="https://guoxiansong.github.io/homepage/index.html" target=_blank rel=noopener>Guoxian Song</a>, <a href="https://ssangx.github.io/" target=_blank rel=noopener>Shen Sang</a>, <a href="https://tiancheng-zhi.github.io/" target=_blank rel=noopener>Tiancheng Zhi</a>, <a href="https://scholar.google.com/citations?user=fv8F6CEAAAAJ&hl=en" target=_blank rel=noopener>Jing Liu</a>, <a href="http://linjieluo.com/" target=_blank rel=noopener>Linjie Luo</a>, and <a href=https://people.ict.usc.edu/~soleymani/ target=_blank rel=noopener>Mohammad Soleymani</a><br>
		<em>IEEE/CVF Winter Conference on Applications of Computer Vision</em> (<i><b>WACV</b></i>), 2024.  <b>(Algorithms Track)</b>
		<p></p>
		<p>
			[<a href="" target="_blank">project page</a>]
			[<a href="https://arxiv.org/abs/2308.12380" target="_blank">paper</a>]
			[<a href="https://github.com/ihp-lab/FG-Net" target="_blank">code</a>]
			[<a href="" target="_blank">video</a>]
		</p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>

    <tr>
		<td width="306">
		<img src="images/rc.jpg" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>RC-MVSNet: Unsupervised Multi-View Stereo with Neural Rendering</b> <br>
			<br>
			<b>Di Chang</b>, <a href=https://aljazbozic.github.io/ target=_blank rel=noopener>Alja≈æ Bo≈æic</a>, <a href="https://people.epfl.ch/tong.zhang?lang=en" target=_blank rel=noopener>Tong Zhang</a>, Qingsong Yan, Yingcong Chen, <a href=https://people.epfl.ch/sabine.susstrunk target=_blank rel=noopener>Sabine S√ºsstrunk</a> and <a href=https://niessnerlab.org/ target=_blank rel=noopener>Matthias Nie√üner</a><br>
			<!-- <b>Di Chang</b>, <a>Alja≈æ Bo≈æiƒç, Tong Zhang, Qingsong Yan, Yingcong Chen, Sabine S√ºsstrunk and Matthias Nie√üner <br> -->
		<em>European Conference on Computer Vision</em> (<i><b>ECCV</b></i>), 2022.
		<!-- <em>Arxiv Preprint</em> (<i><b>Under Review</b></i>), 2022. -->
		<p></p>
		<p>
			[<a href="https://boese0601.github.io/rc-mvsnet/" target="_blank">project page</a>]
			[<a href="https://arxiv.org/abs/2203.03949" target="_blank">paper</a>]
			[<a href="https://github.com/Boese0601/RC-MVSNet" target="_blank">code</a>]
			[<a href="https://www.youtube.com/watch?v=I_Q47TxTLbs" target="_blank">video</a>]
		</p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>

    <tr>
		<td width="306">
		<img src="images/gbinet.JPG" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>Generalized Binary Search Network for Highly-Efficient Multi-View Stereo</b> <br>
			<br>
		<a href="https://mizhenxing.github.io/">Zhenxing Mi</a>, <b>Di Chang</b> and <a href="https://www.danxurgb.net/index.html">Dan Xu</a> <br>
		<em>IEEE/ CVF International Conference on Computer Vision and Pattern Recognition</em> (<i><b>CVPR</b></i>), 2022.
		<p></p>
		<p>
			[<a href="https://mizhenxing.github.io/gbinet/" target="_blank">project page</a>]
			[<a href="https://arxiv.org/abs/2112.02338" target="_blank">paper</a>]
            [<a href="https://github.com/MiZhenxing/GBi-Net" target="_blank">code</a>]
		</p>

		<!-- <p><strong style="color:blue">Oral Presentation</strong></p> -->
		</td>
	</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>




</table>
<br>

<h2><a id="C4" ><font color="#CB4335">Intern & Work Experience</font></a></h2>

<table>
	<tbody>
		<tr>
			<td width="800">
<h4>TikTok, Los Angeles, CA, USA (Aug. 2023 - Nov. 2023) </h4>
	  <ul>
        <li>Position: Research Scientist Intern (Part-time) at ByteDance AI Lab US</li>
		  <li>Supervisor: Dr. <a  target="_blank" href=https://seasonsh.github.io/ rel="external"> Yichun Shi </a>, Dr. <a  target="_blank" href=https://guoxiansong.github.io/homepage/index.html rel="external"> Guoxian Song </a>, Dr. <a  target="_blank" href=https://hongyixu37.github.io/homepage/ rel="external"> Hongyi Xu </a>, and Dr. <a  target="_blank" href=https://scholar.google.com/citations?user=_MAKSLkAAAAJ&hl=en target="_blank" rel="external">Xiao Yang</a></li>
        <li>Project: Half-body Motion Transfer with Diffusion Models </li>
    </ul>
</td>
<td>
	<img id="school_logo" src="./images/TikTok.jpeg" height="100px">
</td>
</tr>
<tr></tr>
</tbody></table>

<table>
	<tbody>
		<tr>
			<td width="800">
<h4>TikTok, San Jose, CA, USA (May. 2023 - Aug. 2023) </h4>
	  <ul>
        <li>Position: Research Scientist Intern at ByteDance AI Lab US</li>
		<li>Supervisor: Dr. <a  target="_blank" href=https://seasonsh.github.io/ rel="external"> Yichun Shi </a>, Dr. <a  target="_blank" href=https://guoxiansong.github.io/homepage/index.html rel="external"> Guoxian Song </a>, Dr. <a  target="_blank" href=https://hongyixu37.github.io/homepage/ rel="external"> Hongyi Xu </a>, and Dr. <a  target="_blank" href=https://scholar.google.com/citations?user=_MAKSLkAAAAJ&hl=en target="_blank" rel="external">Xiao Yang</a></li>
        <li>Project: Text-guided Half-body Image Editing with Diffusion Models </li>
    </ul>
</td>
<td>
	<img id="school_logo" src="./images/TikTok.jpeg" height="100px">
</td>
</tr>
<tr></tr>
</tbody></table>

<table>
	<tbody>
		<tr>
			<td width="800">
<h4>EPFL, Lausanne, Switzerland (Jul. 2022 - Oct. 2022) </h4>
	  <ul>
        <li>Position: Summer@EPFL (Top 2% from the candidates in the world) hired by <a  target="_blank" href=https://www.epfl.ch/labs/ivrl/ target="_blank" rel="external">IVRL</a></li>
		  <li>Supervisor: Dr. <a  target="_blank" href=https://sites.google.com/view/tong-zhang rel="external"> Tong Zhang </a>
			and Prof. <a  target="_blank" href=https://people.epfl.ch/sabine.susstrunk?lang=en target="_blank" rel="external"> Sabine S√ºsstrunk</a></li>
        <li>Project: Video Synthesis with Diffusion Models </li>
    </ul>
</td>
<td>
	<img id="school_logo" src="./images/EPFL.png" height="100px">
</td>
</tr>
<tr></tr>
</tbody></table>
<!-- 
<table>
	<tbody>
		<tr>
			<td width="800">
	<h4> UCSD, San Diego, USA  (Remote Collaboration) </h4>
	<ul>
	  <li>Position: Research Intern in <a  target="_blank" href=https://xiaolonw.github.io/ target="_blank" rel="external">Prof. Wang's Group</a></li>
		<li>Supervisor: Prof. <a  target="_blank" href=https://xiaolonw.github.io/ target="_blank" rel="external"> Xiaolong Wang </a></li>
	  <li>Project: Video Synthesis with Diffusion Models <b>Ongoing Project</b> </li>
  </ul>
</td>
<td>
	<img id="school_logo" src="./images/UCSD.png" height="100px">
</td>
</tr>
<tr></tr>
</tbody></table> -->

<!--    <img id="school_logo" src="./pics/uII.png">-->
<table>
	<tbody>
		<tr>
			<td width="800"> 
      <h4> TUM, Munich, Bayern, Germany  (Mar. 2022 - Aug. 2022) </h4>
	  <ul>
        <li>Position: Guided Research in <a  target="_blank" href=https://www.3dunderstanding.org target="_blank" rel="external">3D AI Group</a></li>
        <li>Supervisor: Prof. <a  target="_blank" href=https://www.3dunderstanding.org/team.html target="_blank" rel="external"> Angela Dai </a></li>
        <li>Project: Single-View Reconstruction and Category-level NeRF</li>
    </ul>
</td>
<td>
	<img id="school_logo" src="./images/TUM.jpg" height="100px">
</td>
</tr>
<tr></tr>
</tbody></table>

<!--    <img id="school_logo" src="./pics/Flexiv.png">-->
          <!--<h4> The University of North Carolina at Chapel Hill, NC, USA  & <br> Shanghai United ImagingIntelligence Co., Ltd, China  (Jun. 2018 - Nov. 2018)</br> </h4>-->
		  <table>
			<tbody>
				<tr>
					<td width="800"> 
		  <h4> TUM, Munich, Bayern, Germany  (Aug. 2021 - Mar. 2022) </h4>
          <ul>
            <li>Position: Research Praktikum in <a  target="_blank" href="https://www.niessnerlab.org/" target="_blank" rel="external">Visual Computing Group</a></li>
            <li>Supervisor: Prof.<a  target="_blank" href=https://www.niessnerlab.org/members/matthias_niessner/profile.html target="_blank" rel="external"> Matthias Niessner</a> and
				M.Sc <a  target="_blank" href=https://aljazbozic.github.io/ target="_blank" rel="external"> Alja≈æ Bo≈æiƒç </a>
			</li>
            <li>Project: Unsupervised Multi-View Stereo --> <b>ECCV 2022</b> </li>
            <!-- <br/>
            <br/> -->
            <!-- <td width="306">
            <img src="pics/masage.gif" width="285px" height= "180px" style="box-shadow: 4px 4px 8px #888">
            </td> -->
      </ul>
	</td>
	<td>
		<img id="school_logo" src="./images/TUM.jpg" height="100px">
	</td>
	</tr>
	<tr></tr>
	</tbody></table>
<!--    <img id="school_logo" src="./pics/uII.png">-->
<table>
	<tbody>
		<tr>
			<td width="800">
      <h4> HKUST, Hong Kong, China  (Mar. 2021 - Sep. 2021) </h4>
	  <ul>
        <li>Position: Research Intern in <a  target="_blank" href="https://www.danxurgb.net/index.html" target="_blank" rel="external">HKUST Vision Group (MM-Lab at HKUST)</a></li>
        <li>Supervisor: Prof.<a  target="_blank" href=https://www.danxurgb.net/index.html target="_blank" rel="external"> Dan Xu</a>
        and M.Sc <a  target="_blank" href=https://mizhenxing.github.io/ target="_blank" rel="external"> Zhenxing Mi </a></li>
        <li>Project: Multi View Stereo Depth Estimation --> <b>CVPR 2022</b>  </li>
    </ul>
</td>
<td>
	<img id="school_logo" src="./images/HKUST.jpg" height="100px">
</td>
</tr>
<tr></tr>

</tbody></table>


<h2><font color="#CB4335">Students</font></h2>
      <ul>
		<li>
			<a  target="_blank" href=https://www.linkedin.com/in/jessica-fu-60a504254/ target="_blank" rel="external">Jessica Fu</a>. (Undergraduate student at USC, recruited through CURVE Fellowship. 2023 Fall, 2024 Spring)</li>		  
		<li>
			<a  target="_blank" href=https://www.linkedin.com/in/kevin-hopkins-1471781ba/ target="_blank" rel="external">Kevin Hopkins</a>. (Master student at USC. 2023 Fall, 2024 Spring)</li>
		<li>
			<a  target="_blank" href=https://www.linkedin.com/in/elliexing/ target="_blank" rel="external">Ellie Xing</a>. (Undergraduate student at USC, recruited through CURVE Fellowship. 2024 Spring)</li>
		<li>
			<a  target="_blank" href=https://www.linkedin.com/in/hongkun-kevin-gong-7296a8262/ target="_blank" rel="external">Hongkun Gong</a>. (Undergraduate student at USC. 2024 Spring)</li>
      </ul>

<br>

<!-- <h2><font color="#CB4335">Honors and Awards</font></h2>
      <ul> -->
		<!-- <li>
			Mar 2022 <b>Outstanding UG graduates</b> of DUT </li>      
		<li>
			Oct 2021 <b>Outstanding Undergraduate</b> of DUT </li>     
        <li>
          May 2021 <b>The Third prize</b> 2021 China Underwater Robot Professional Contest - Acoustics Track </li>
		<li>
          May 2021 <b>The Second prize</b> 2021 China Underwater Robot Professional Contest - Optics Track </li>
		<li>
			Oct 2020 <b>Outstanding Undergraduate</b> of DUT </li>     
		<li>
			Oct 2019 <b>Outstanding Undergraduate</b> of DUT </li>        
      </ul> -->

<!-- <br> -->

<h2><font color="#CB4335">Academic Service</font></h2>
Reviewer of the following conferences/journals:
<br>
<br>
ECCV 2022<br>
NeurIPS 2022<br>
FG 2024<br>
CVPR 2024<br>
<!--2021 IEEE CVPR WORKSHOP ON FAIR, DATA EFFICIENT AND TRUSTED COMPUTER VISION<br>-->


<br>


<h2><font color="#CB4335">Teaching</font></h2>
      <ul>
		<li>
			Graduate Teaching Assistant, CSCI 103 Introduction to Programming - 2022 Fall</li>
		<li>
			Graduate Teaching Assistant, CSCI 535 Multimodal Probabilistic Learning of Human Communication - 2024 Spring</li>
        <!-- <li>
          Sep 2017 <b>National Scholarship(Graduate)</b>, (highest honor for graduates) <strong style="color:blue">top 1% nationwide</strong></li>
        <li>
          Sep 2015 <b>National Scholarship(Undergraduate)</b>, (highest honor for undergraduates, top 2% nationwide) </li>
		<li>
          May 2018 <b>KaiYuan Motivational Scholarship</b> <strong style="color:blue">top 0.5% in Shanghai Jiao Tong University</strong></li>
        <li>
          Sep 2015 <b>Presidential Scholarship</b>, (highest honor in Shandong University) <strong style="color:blue">top 0.2% in Shan Dong University</strong></li>
        <li>
          Sep 2015 <b>BaoGang Excellent student Scholarship</b>, (4 Places per year at Shandong University) </li>
		<li>
          Sep 2015 &amp; Sep 2014 &amp; Sep 2015</b> <b>First Prize Scholarship</b> (Top 6% in China,three-year continuous)</li> -->
      </ul>

<br>

<h2><font color="#CB4335">Miscellaneous</font></h2>
      <ul>
		<li>
			(10 yrs +) üé∑Clarinet, professional player, once level 9 certification of The Central Conservatory of Music.</li>		  
		<li>
			(8 yrs +) üè∏Badminton, I was a member of DUT EE Department badminton team.</li>
		<li>
			(5 yrs +) üéÆVideo Games, I am a lover of League of Legends, highest rank: Platinum II of EU server S12.</li>
		<li>
			(6 months) üèÅCar Racing, I love racing with my Chevy Camaro SS. Find me at Angeles Crest Highway or Azusa on weekends!</li>
      </ul>

<br>




<div id="footer1">
	<h2> </h2>
		<div align="center">
		  <small>This page has been visited for
			<a href="https://www.easycounter.com/">
			<img src="https://www.easycounter.com/counter.php?dichang" border="0" alt="HTML Hit Counter"></a>times</small>
		  </div> 
	</div>
  <p>
	<center>
	<div align="center" style="width:20%">
	  <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=grr8tSJTdsbdU-vHO6Of-5W7jpLTZvSVYTu6BUgf02M"></script>
	</div>        
	</center>
  </p>
  

<p align="center"><font color="#999999">Last update: Jan. 15, 2024</font></p>



</body>

</html>

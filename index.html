<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
    <head>
    <meta name="google-site-verification" content="eoPCGBBxDIK0Ff9Dk_dXsuHMTNzzSEZMbsfO4zriBK8" />
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <link rel="shortcut icon" href="./images/doge.ico">
	<meta name="keywords" content="常迪, Chang Di, 常迪, CHANG Di, 常迪, Di CHANG, University of Southern California, USC, Technical University of Munich, TUM，Dalian University of Technology，DLUT, DUT, 大连理工大学, 慕尼黑工业大学, 南加州大学, München, Munich, 慕尼黑, California, 加利福尼亚州">
	<meta name="description" content="Di CHANG&#39;s Home Page">
<!--    <link href="main.css" media="all" rel="stylesheet">-->
    <link rel="stylesheet" href="jemdoc.css" type="text/css">
    <title>Di CHANG | 常迪</title>
    </head>

<body>


<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">
					<h1 style="color:#FF0000">Di (Kilian) Chang</h1><h1>
					<h1 style="color:#FF0000">常迪</h1><h1>
				</h1></div>

				<h3>CS Ph.D.  @ <a href="https://www.usc.edu/" target="_blank">University of Southern California</a></h3>
				<h3>Research Scientist Intern @ <a href="https://ai.meta.com/" target="_blank">Meta</a></h3>
<!--                <h3>University of Southern California</h3>-->
				<p>
					<a href="https://www.cs.usc.edu/" target="_blank">Department of Computer Science</a> <br>
					<a href="https://viterbischool.usc.edu/" target="_blank">Viterbi School of Engineering</a><br>
					<a href="https://www.usc.edu/" target="_blank">University of Southern California</a> <br>

<!--					Rm B06, Hedco Neurosciences Building, 3641 Watt Way, Los Angeles, CA 90089-2520, USA <br>-->

					Email1: dichang at usc dot edu (primary) <br>
					Email2: dchang at ict dot usc dot edu <br>
				</p>
				<p> <a href="https://scholar.google.com.hk/citations?hl=en&user=68wkMTgAAAAJ" target="_blank"><img src="./pics/google_scholar3.png" height="40px" style="margin-bottom:-3px"></a>
					<a href="https://github.com/Boese0601" target="_blank"><img src="./pics/github_s.jpg" height="40px" style="margin-bottom:-3px"></a>
					<a href="https://twitter.com/DiChang10" target="_blank"><img src="./images/twitter.png" height="40px" style="margin-bottom:-3px"></a>
					<a href="https://www.instagram.com/kiliandi10/" target="_blank"><img src="./files/ins.png" height="40px" style="margin-bottom:-3px"></a>
                    <a href="https://www.linkedin.com/in/di-chang-004784206/" target="_blank"><img src="./pics/LinkedIn2.png" height="40px" style="margin-bottom:-3px"></a>
                    <!-- <a href="files/CV_Di.pdf"><img src="./pics/cv2.png" height="40px" style="margin-bottom:-3px"></a> -->
					&nbsp &nbsp
					<!-- <a href="#C1">[<font <font size="3" color="#CB4335"><b>About Me</b></font>] </a> -->
					<a href="#C2">[<font size="3" color="#CB4335"><b>News</b></font>]</a>
					<a href="#edu">[<font size="3" color="#CB4335"><b>Education</b></font>]</a>
					<a href="#C3">[<font size="3" color="#CB4335"><b>Publications</b></font>]</a>
					<a href="#C4">[<font size="3" color="#CB4335"><b>Experience</b></font>]</a></li>
				</p>
			</td>
			<td>
				<img src="./images/dichang.png" border="0" width="230"><br>
<!--				<img src="pics/cover.png" border="0" width="540"><br>-->
			</td>
		</tr><tr>
	</tr></tbody>
</table>




<h2><a id="C1" ><font color="#CB4335">About Me</font></a></h2>
<p> <a href="https://www.cs.usc.edu/"><img src="./pics/USC_logo.png" height="100px" style="margin-bottom:-3px"></a>&nbsp &nbsp &nbsp
	<a href="https://www.tiktok.com/en/"><img src="./images/TikTok.jpeg" height="100px" style="margin-bottom:-3px"></a>&nbsp &nbsp &nbsp
	<a href="https://about.meta.com/realitylabs/"><img src="./images/meta.jpg" height="90px" style="margin-bottom:-3px"></a>&nbsp &nbsp &nbsp
	<a href="https://www.tum.de/en/"><img src="./images/TUM.jpg" height="100px" style="margin-bottom:-3px"></a>&nbsp &nbsp &nbsp
	<a href="https://www.epfl.ch/en/"><img src="./images/EPFL.png" height="120px" style="margin-bottom:-3px"></a>&nbsp &nbsp &nbsp &nbsp
	<br>
	<br>

</p>
<p>I am a <strike>first-year</strike> <strike>second-year</strike> third-year Ph.D. student in the Department of Computer Science at <a  href="https://www.cs.usc.edu/">University of Southern California</a> (USC) with Prof. <a  target="_blank" href=https://people.ict.usc.edu/~soleymani/ target="_blank" rel="external">Mohammad Soleymani</a> of <a  href="https://www.ihp-lab.org/">IHP-Lab</a>. I'm also a research scientist intern at Meta with Dr. <a  target="_blank" href=https://www.linkedin.com/in/stephanegrabli/ rel="external">Stephane Grabli</a>, 
			Dr. <a  target="_blank" href=https://aljazbozic.github.io/ rel="external">Aljaz Bozic</a>, and
			Dr. <a  target="_blank" href=https://sekunde.github.io/ rel="external">Ji Hou</a>. I was a student researcher at ByteDance Seed Vision Research,  working with Dr. <a  target="_blank" href=https://seasonsh.github.io/ rel="external"> Yichun Shi </a> and Dr. <a target="_blank" href=https://pengwangucla.github.io/peng-wang.github.io/  rel="external">Peng Wang</a> in the spring of 2025. During my PhD at USC, I'm fortunate to have collaborated with Prof. <a  href="https://web.stanford.edu/~gordonwz/">Gordon Wetzstein</a> from Stanford University, Prof. <a href="https://vision.ai.illinois.edu/narendra-ahuja/">Narendra Ahuja</a> from University of Illinois Urbana-Champaign, and their students.
	I was a Research Scientist Intern at TikTok-ByteDance Intelligent Creation Lab,  working with Dr. <a  target="_blank" href=https://hongyixu37.github.io/homepage/ rel="external"> Hongyi Xu </a> and Dr. <a target="_blank" href=http://linjieluo.com/  rel="external">Linjie Luo</a> during 2024 summer, and with Dr. <a  target="_blank" href=https://seasonsh.github.io/ rel="external"> Yichun Shi </a> and Dr. <a target="_blank" href= https://scholar.google.com/citations?user=_MAKSLkAAAAJ&hl=en  rel="external">Xiao Yang</a> during 2023 summer.

</p>
	Before that, I spent four wonderful years during my undergraduate at <a href="https://en.dlut.edu.cn/">Dalian University of Technology</a> and <a href=https://www.tum.de/en/ target="_blank" >Technical University of Munich</a>, studying Informatics and Information Engineering.
	I'm honored to be advised by Prof. <a  target="_blank" href=https://www.niessnerlab.org/members/matthias_niessner/profile.html target="_blank" rel="external"> Matthias Niessner </a> and
	Dr. <a  target="_blank" href=https://aljazbozic.github.io/ target="_blank" rel="external"> Aljaž Božič </a> during my praktikum at <a  target="_blank" href="https://www.niessnerlab.org/" target="_blank" rel="external">Visual Computing Group</a>.
	I spent a wonderful summer in 2022 with Dr. <a  target="_blank" href=https://sites.google.com/view/tong-zhang rel="external"> Tong Zhang </a>
	and Prof. <a  target="_blank" href=https://people.epfl.ch/sabine.susstrunk?lang=en target="_blank" rel="external"> Sabine Süsstrunk</a> at EPFL CS and in 2021 with Prof. <a  target="_blank" href=https://www.danxurgb.net/index.html target="_blank" rel="external"> Dan Xu </a> at HKUST CSE.
</p>
	I'm interested in Generative Vision Models, 3D Reconstruction and Motion Synthesis. My current and past research focuses include:
<ul>
	  <li>Multi-View Geometry and Dynamic 3D Generation. </li>
	  <li>Image and Video Generation with Diffusion Models.</li>
	  <li>Facial Expression Analysis and Affective Computing.</li>
	</ul>

<p> <b>Research opportunities</b>:<br>
	For USC undergraduate students: We have openings for interns through <a href=https://viterbiundergrad.usc.edu/research/curve/ target=_blank rel=noopener>CURVE</a> program. Usually we recruit students (first-time researchers and continuing researchers) during Fall and Spring semesters, please apply early. <br><br>
	For USC master students: Please directly email Prof. <a  target="_blank" href=https://people.ict.usc.edu/~soleymani/ target="_blank" rel="external">Mohammad Soleymani</a> for such inquiries. It would be better if you've attended CSCI 535 and obtained a good grade. <br><br>
	For all other students outside USC: we usually don't have openings during Fall and Spring semesters, but Prof. <a  target="_blank" href=https://people.ict.usc.edu/~soleymani/ target="_blank" rel="external">Mohammad Soleymani</a> sometimes recruits good candidates (Undergrad/Ms/visiting PhD) during the Summer. Email him for further details. <br><br>
	I am happy to collaborate and/or answer questions about my research and my previous study at TUM and current PhD program at USC. If you are interested in research collaboration or have any inquiries about my experience, please send me an email.
</p>





<h2><a id="C2" ><font color="#CB4335">News</font></a></h2>
<ul>

<div style="height:200px;width:fit-content;overflow:auto;background:#FFFFFF;">
	<li>
		<p>[2025/05/27] Our <a href=https://magicpose4d.github.io/ rel=noopener>MagicPose4D</a> has been accepted by TMLR!</p>
	</li>
	<li>
		<p>[2025/05/27] Start my Summer Internship at Meta in San Francisco!</p>
	</li>
	<li>
		<p>[2025/02/26] Our <a href=https://github.com/bytedance/X-Dyna rel=noopener>X-Dyna</a> has been accepted by CVPR 2025 as <b style="color:red">Highlight</b>! See you in Nashville!</p>
	</li>
	<li>
		<p>[2024/12/02]  I will join <a href="https://about.meta.com/realitylabs/">Meta Reality Lab</a> and <a href="https://ai.meta.com/meta-ai/">GenAI</a> in San Francisco, CA as a Research Scientist Intern during 2025 Summer.</p>
	</li>
	<li>
		<p>[2024/11/27]  Joined <a href="https://team.doubao.com/en/" target="_blank">Seed Vision</a> at TikTok as a student researcher. Excited to work with my previous mentor Dr. <a  target="_blank" href=https://seasonsh.github.io/ rel="external">Yichun Shi</a>.</p>
	</li>
	<li>
		<p>[2024/07/01]  Our <a href=https://boese0601.github.io/dim/ rel=noopener>Dyadic-Interaction-Modeling</a> has been accepted by ECCV 2024! See you in Milan, Italy!</p>
	</li>
	<li>
		<p>[2024/05/20]  Start my Summer Internship at <a href="https://www.tiktok.com/en/">TikTok</a> (San Jose Office in CA). Excited to return to my previous team and work with Dr. <a  target="_blank" href=https://hongyixu37.github.io/homepage/ rel="external">Hongyi Xu</a>.</p>
	</li>
	<li>
		<p>[2024/05/01] Our <a href=https://freedomgu.github.io/DiffPortrait3D/ rel=noopener>MagicPose</a> has been accepted by ICML 2024! See you in Vienna, Austria!</p>
	</li>
	<li>
		<p>[2024/02/26] Our <a href=https://freedomgu.github.io/DiffPortrait3D/ rel=noopener>DiffPortrait3D</a> has been accepted by CVPR 2024 as <b style="color:red">Highlight</b>! See you in Seattle!</p>
	</li>
	<li>
		<p>[2023/08/14] Our <a href=https://boese0601.github.io/fgnet/ target=_blank rel=noopener>FG-Net</a> and <a href=https://boese0601.github.io/fgnet/ target=_blank rel=noopener>LibreFace</a> has been accepted by WACV 2024! Find me at Waikoloa, Hawaii.</p>
	</li>
	<li>
		<p>[2023/05/22]  Start my Summer Internship at <a href="https://www.tiktok.com/en/">TikTok</a> (San Jose Office in CA). Looking forward to building connections with talents in the Bay Area! </p>
	</li>
	<li>
		<p>[2022/08/19]  Today I start my Ph.D. at <a href="https://www.cs.usc.edu/">USC Viterbi Computer Science</a>! Fight on, Trojans!  </p>
	</li>
	<li>
		<p>[2022/07/04]  My first single-first-author paper <a href=https://www.niessnerlab.org/projects/chang2022rcmvsnet.html target=_blank rel=noopener>RC-MVSNet</a> has been accepted by ECCV 2022! See you in Tel Aviv!</p>
	</li>
	<li>
		<p>[2022/04/08]  I'm joining <a href=https://www.ihp-lab.org/ target=_blank rel=noopener>IHP-Lab</a> at <a href=https://www.cs.usc.edu/ target=_blank rel=noopener>USC</a> as a PhD student, see you in Los Angeles!</p>
	</li>
	<li>
		<p>[2022/03/15] Our <a href=https://mizhenxing.github.io/gbinet/ target=_blank rel=noopener>GBi-Net</a> has been accepted by CVPR 2022!</p>
	<li>
		<p>[2022/03/07] I will join <a href=https://www.3dunderstanding.org target=_blank rel=noopener>3D AI Lab</a> at <a href=https://www.tum.de/en/ target=_blank rel=noopener>Technische Universität München</a> as a guided research student with Professor Angela Dai.</p>
	</li>
	<li>
		<p>[2022/01/15] I will join <a href=https://www.epfl.ch/labs/ivrl/ target=_blank rel=noopener>Image and Visual Representation Lab</a> at <a href=https://www.epfl.ch/en/ target=_blank rel=noopener>École Polytechnique Fédérale de Lausanne</a> as a research intern/visiting researcher.
	</li>
	<li>
		<p>[2021/10/15] I will join <a href=https://niessnerlab.org/ target=_blank rel=noopener>Visual Computing & Artificial Intelligence Lab</a> at <a href=https://www.tum.de/en/ target=_blank rel=noopener>Technische Universität München</a> with Professor Matthias Niessner.
	</li>
	<li>
		<p>[2021/03/04] I will join <a href=https://www.danxurgb.net/index.html target=_blank rel=noopener>Prof.Xu&rsquo;s vision group</a> at <a href=https://hkust.edu.hk/home target=_blank rel=noopener>HKUST</a> as a research intern during summer 2021.
	</li>
	

</div>
</ul>
<br>


<h2><a id="C4" ><font color="#CB4335">Talks</font></a></h2>

<table>
	<tbody>
		<tr>
			<td width="800">
<h4>Atmanity - 05/20/2025</h4>
	  <ul>
        <li>Title: Intelligent Human Motion Animation. </li>
    </ul>
</td>
<td>
	<img id="atmanity_logo" src="./images/atmanity.png" height="100px">
</td>
</tr>
<tr></tr>
</tbody></table>


<table>
	<tbody>
		<tr>
			<td width="800">
<h4>EPFL School of Computer and Communication Sciences - 09/26/2024</h4>
	  <ul>
        <li>Title: Human-Centric Generative Vision Models. &nbsp &nbsp &nbsp Slides: <a href="https://docs.google.com/presentation/d/11ZwXZiBjXIoxb7BfCu_xWfF4ZuJ2c5FXujXnhkiaqKo/edit?usp=sharing">Here</a>. </li>
		<li>Hosted by: <a href="https://www.epfl.ch/labs/ivrl/">Image and Visual Representation Lab</a> and <a href="https://www.epfl.ch/labs/cvlab/">Computer Vision Lab</a>.
		</li>
    </ul>
</td>
<td>
	<img id="school_logo" src="./images/EPFL.png" height="100px">
</td>
</tr>
<tr></tr>
</tbody></table>



<h2><a id="C3" ><font color="#CB4335">Preprints</font></a></h2>

<table id="tbPreprints" width="100%">
	<tr>
		<td width="306">
		<img src="images/bytemorph.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>ByteMorph: Benchmarking Instruction-Guided Image Editing with Non-Rigid Motions</b> <br>
			<br>
			<b>Di Chang*</b>, 
			<a href="https://github.com/ljzycmd">Mingdeng Cao*</a>, 
			<a href="https://seasonsh.github.io/">Yichun Shi</a>, 
			<a href="https://www.linkedin.com/in/bo-liu-340313170">Bo Liu</a>, 
			<a href="https://primecai.github.io/">Shengqu Cai</a>, 
			<a href="https://shijiezhou-ucla.github.io/">Shijie Zhou</a>, 
			<a href="https://scholar.google.com/citations?user=78vU1IUAAAAJ&hl=en">Weilin Huang</a>, 
			<a href="https://web.stanford.edu/~gordonwz/">Gordon Wetzstein</a>, 
			<a href="https://www.ihp-lab.org/">Mohammad Soleymani</a>, 
			<a href="https://pengwangucla.github.io/peng-wang.github.io/">Peng Wang</a>
			<br>
			(*equal contribution)<br>
		<em>Arxiv Preprint</em>
		<p></p>
		<p>
			[<a href="https://boese0601.github.io/bytemorph/" target="_blank">project page</a>]
			[<a href="" target="_blank">paper</a>]
			[<a href="https://github.com/ByteDance-Seed/BM-code" target="_blank">code</a>]
			[<a href="https://huggingface.co/datasets/ByteDance-Seed/BM-6M" target="_blank">dataset</a>]
			[<a href="https://huggingface.co/datasets/ByteDance-Seed/BM-Bench" target="_blank">benchmark</a>]
			[<a href="https://huggingface.co/spaces/Boese0601/ByteMorph-Demo" target="_blank">demo</a>]
			<a class="more-link" href="https://github.com/ByteDance-Seed/BM-code" target="_blank"><img alt="GitHub stars" align="right"
				src="https://img.shields.io/github/stars/ByteDance-Seed/BM-code?style=social"></a>
		</p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>

	<tr>
		<td width="306">
		<img src="images/vlm4d.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>VLM4D: Towards Spatiotemporal Awareness in Vision Language Models</b> <br>
			<a href="https://shijiezhou-ucla.github.io/">Shijie Zhou*</a>, 
			<a href="https://asvilesov.github.io/">Alexander Vilesov*</a>,
			<a href="https://sheehan1230.github.io/">Xuehai He*</a>, 
			<a href="http://raywzy.com/">Ziyu Wan</a>, 
			Shuwang Zhang, 
			Aditya Nagachandra, 
			<b>Di Chang</b>, 
			<a href="https://www.dongdongchen.bid/">Dongdong Chen</a>,
			<a href="https://eric-xw.github.io/">Xin Eric Wang</a>,
			<a href="https://samueli.ucla.edu/people/achuta-kadambi/">Achuta Kadambi</a>
			<br>
			(*equal contribution)<br>
		<em>Arxiv Preprint</em>
		<p></p>
		<p>
			[<a href="https://vlm4d.github.io/" target="_blank">project page</a>]
			[<a href="https://vlm4d.github.io/file/VLM4D.pdf" target="_blank">paper</a>]
		</p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>


	<tr>
		<td width="306">
		<img src="images/ditai.gif" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>DiTaiListener: Controllable High Fidelity Listener Video Generation with with Diffusion</b> <br>
			<br>
			<a href="https://cv.maxi.su/">Masksim Siniukov*</a>, <b>Di Chang*</b>, <a href="https://scholar.google.com/citations?hl=en&user=HuuQRj4AAAAJ">Minh Tran</a>, <a href="https://www.linkedin.com/in/hongkun-kevin-gong-7296a8262/">Hongkun Gong</a>, <a href="https://ashutoshchaubey.in/">Ashutosh Chaubey</a>, <a href="https://www.ihp-lab.org/">Mohammad Soleymani</a><br>
			(*equal contribution)<br>
		<em>Arxiv Preprint</em>
		<p></p>
		<p>
			[<a href="https://cv.maxi.su/DiTaiListener/" target="_blank">project page</a>]
			[<a href="https://arxiv.org/abs/2504.04010" target="_blank">paper</a>]
		</p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>



	<tr>
		<td width="306">
		<img src="images/xdancer.gif" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>X-Dancer: Expressive Music to Human Dance Video Generation</b> <br>
			<br>
			<a href="">Zeyuan Chen</a>, <a href="https://hongyixu37.github.io/homepage/">Hongyi Xu</a>, <a href="https://guoxiansong.github.io/homepage/index.html">Guoxian Song</a>, <a href="https://youxie.github.io/">You Xie</a>, <a href="https://zhangchenxu528.github.io/">Chenxu Zhang</a>, Xin Chen, <a href="https://chaowang.info/">Chao Wang</a>, <b>Di Chang</b>, <a href="https://scholar.google.com/citations?user=fqubyX0AAAAJ&hl=en">Linjie Luo</a><br>
		<em>Arxiv Preprint</em>
		<p></p>
		<p>
			<!-- [<a href="https://magicpose4d.github.io/" target="_blank">project page</a>] -->
			[<a href="https://arxiv.org/abs/2502.17414" target="_blank">paper</a>]
			<!-- [<a href="https://github.com/haoz19/MagicPose4D" target="_blank">code</a>] -->
			<!-- <a class="more-link" href="https://github.com/haoz19/MagicPose4D" target="_blank"><img alt="GitHub stars" align="right"
				src="https://img.shields.io/github/stars/haoz19/MagicPose4D?style=social"></a> -->
			<!-- [<a href="https://www.youtube.com/watch?v=VPJe6TyrT-Y" target="_blank">video</a>] -->
		</p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>


	<tr>
		<td width="306">
		<img src="images/MVS_Survey.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>Learning-based Multi-View Stereo: A Survey</b> <br>
			<br>
			<a href="https://fangjinhuawang.github.io/">Fangjihua Wang*<span>&#8224;</span></a>, 
			<a href="https://qtzhu.me/">Qingtian Zhu*</a>, <b>Di Chang*</b>, 
			<a href="https://zerg-overmind.github.io/">Quankai Gao</a>, 
			<a href="https://junlinhan.github.io/">Junlin Han</a>, 
			<a href="https://sites.google.com/view/tong-zhang">Tong Zhang</a>, 
			<a href="https://scholar.google.com/citations?user=cHia5p0AAAAJ&hl=en">Richard Hartley</a>, <a href="https://people.inf.ethz.ch/marc.pollefeys/">Marc Pollefeys</a><br>
			(*equal contribution &nbsp <span>&#8224;</span>project lead)<br>
		<em>Arxiv Preprint</em>
		<p></p>
		<p>
			[<a href="https://arxiv.org/abs/2408.15235" target="_blank">paper</a>]
		</p>
		</td>
	</tr>

	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>


</table>
<br>


<h2><a id="C3" ><font color="#CB4335">Selected Publications</font></a> [<a href=https://scholar.google.com.hk/citations?hl=en&user=68wkMTgAAAAJ>Google Scholar</a>]</h2>

<table id="tbPublications" width="100%">
	    <tr>
		<td width="306">
		<img src="images/magicpose4d.gif" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>MagicPose4D: Crafting Articulated Models with Appearance and Motion Control</b> <br>
			<br>
			<a href="https://haoz19.github.io/">Hao Zhang*</a>, <b>Di Chang*</b>, <a href="https://www.linkedin.com/in/fang-li-8ab696223/">Fang Li</a>, <a href="https://www.ihp-lab.org/">Mohammad Soleymani</a><span>&#8224;</span>, <a href="https://vision.ai.illinois.edu/narendra-ahuja/">Narendra Ahuja</a><span>&#8224;</span><br>
			(*equal contribution &nbsp <span>&#8224;</span> equal advise)<br>
		<em>Transactions on Machine Learning Research</em> (<i><b>TMLR</b></i>).
		<p></p>
		<p>
			[<a href="https://magicpose4d.github.io/" target="_blank">project page</a>]
			[<a href="https://arxiv.org/abs/2405.14017" target="_blank">paper</a>]
			[<a href="https://github.com/haoz19/MagicPose4D" target="_blank">code</a>]
			<a class="more-link" href="https://github.com/haoz19/MagicPose4D" target="_blank"><img alt="GitHub stars" align="right"
				src="https://img.shields.io/github/stars/haoz19/MagicPose4D?style=social"></a>

		</p>
		</td>
	</tr>

	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>


	<tr>
		<td width="306">
		<img src="images/xdyna.gif" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>X-Dyna: Expressive Dynamic Human Image Animation</b> <br>
			<br>
			<b>Di Chang</b>, 
			<a href="https://hongyixu37.github.io/homepage/">Hongyi Xu*</a>, 
			<a href="https://youxie.github.io/">You Xie*</a>, 
			<a href="https://hlings.github.io/">Yipeng Gao*</a>, 
			<a href="https://zhengfeikuang.com/">Zhengfei Kuang*</a>, 
			<a href="https://primecai.github.io/">Shengqu Cai*</a>, 
			<a href="https://zhangchenxu528.github.io/">Chenxu Zhang*</a>, 
			<a href="https://guoxiansong.github.io/homepage/index.html">Guoxian Song</a>, 
			<a href="https://chaowang.info/">Chao Wang</a>, 
			<a href="https://seasonsh.github.io/">Yichun Shi</a>, 
			<a href="https://zeyuan-chen.com/">Zeyuan Chen</a>, 
			<a href="https://shijiezhou-ucla.github.io/">Shijie Zhou</a>, 
			<a href="https://scholar.google.com/citations?user=fqubyX0AAAAJ&hl=en">Linjie Luo</a>, 
			<a href="https://web.stanford.edu/~gordonwz/">Gordon Wetzstein</a>, 
			<a href="https://www.ihp-lab.org/">Mohammad Soleymani</a>, 
			<br>
			(*equal contribution as second authors)<br>
		<em>IEEE/CVF Computer Vision and Pattern Recognition Conference</em> (<i><b>CVPR</b></i>), 2025. <b style="color:red">(Highlight)</b>
		<p></p>
		<p>
			[<a href="https://x-dyna.github.io/xdyna.github.io/" target="_blank">project page</a>]
			[<a href="https://arxiv.org/abs/2501.10021" target="_blank">paper</a>]
			[<a href="https://github.com/bytedance/X-Dyna" target="_blank">code</a>]
			<a class="more-link" href="https://github.com/bytedance/X-Dyna" target="_blank"><img alt="GitHub stars" align="right"
				src="https://img.shields.io/github/stars/bytedance/X-Dyna?style=social"></a> 
		</p>
		</td>
	</tr>

	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>

	<tr>
		<td width="306">
		<img src="images/dim.gif" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>DIM: Dyadic Interaction Modeling for Social Behavior Generation</b> <br>
			<br>
			<a href="https://scholar.google.com/citations?hl=en&user=HuuQRj4AAAAJ">Minh Tran*</a>, <b>Di Chang*</b>, <a href="https://scholar.google.com/citations?hl=en&user=5w0f0OQAAAAJ">Maksim Siniukov</a>, <a href="https://www.ihp-lab.org/">Mohammad Soleymani</a><br>
			(*equal contribution)<br>
			<em>European Conference on Computer Vision</em> (<i><b>ECCV</b></i>), 2024.
		<p></p>
		<p>
			[<a href="https://boese0601.github.io/dim/" target="_blank">project page</a>]
			[<a href="https://arxiv.org/abs/2403.09069" target="_blank">paper</a>]
			[<a href="https://github.com/Boese0601/Dyadic-Interaction-Modeling" target="_blank">code</a>]
			<!-- [<a href="https://www.youtube.com/watch?v=VPJe6TyrT-Y" target="_blank">video</a>] -->
			<a class="more-link" href="https://github.com/Boese0601/Dyadic-Interaction-Modeling" target="_blank"><img alt="GitHub stars" align="right"
				src="https://img.shields.io/github/stars/Boese0601/Dyadic-Interaction-Modeling?style=social"></a>
		</p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>
	<tr>
		<td width="306">
		<img src="images/magicdance.gif" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>MagicPose: Realistic Human Poses and Facial Expressions Retargeting with Identity-aware Diffusion.</b> <br>
			<br>
			<b>Di Chang</b>, <a href="https://seasonsh.github.io/">Yichun Shi</a>, <a href="https://zerg-overmind.github.io/">Quankai Gao</a>, <a href="https://www.linkedin.com/in/jessica-fu-60a504254/">Jessica Fu</a>, <a href="https://hongyixu37.github.io/homepage/">Hongyi Xu</a>, <a href="https://guoxiansong.github.io/homepage/index.html">Guoxian Song</a>, <a href="https://scholar.google.com/citations?user=0TIYjPAAAAAJ&hl=en">Qing Yan</a>, <a href="https://scholar.google.com/citations?user=hPXUR0cAAAAJ&hl=en">Yizhe Zhu</a>, <a href="https://scholar.google.com/citations?user=_MAKSLkAAAAJ&hl=en">Xiao Yang</a>, <a href="https://www.ihp-lab.org/">Mohammad Soleymani</a><br>
		<em> International Conference on Machine Learning (<i><b>ICML</b></i>), 2024.</em>
		<p></p>
		<p>
			[<a href="https://boese0601.github.io/magicdance/" target="_blank">project page</a>]
			[<a href="https://arxiv.org/abs/2311.12052" target="_blank">paper</a>]
			[<a href="https://github.com/Boese0601/MagicDance" target="_blank">code</a>]
			[<a href="https://www.youtube.com/watch?v=VPJe6TyrT-Y" target="_blank">video</a>]
			<a class="more-link" href="https://github.com/Boese0601/MagicDance" target="_blank"><img alt="GitHub stars" align="right"
				src="https://img.shields.io/github/stars/Boese0601/MagicDance?style=social"></a>
		</p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>
   
	<tr>
		<td width="306">
		<img src="images/diff3d.gif" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>DiffPortrait3D: Controllable Diffusion for Zero-Shot Portrait View Synthesis</b> <br>
			<br>
				<a href="https://yuming-gu.com/">Yuming Gu</a>,
				  <a href="https://ge.in.tum.de/about/you-xie/">Xie You</a>,
				<a href="http://www-scf.usc.edu/~hongyixu/">Hongyi Xu</a>,
				<a href="https://guoxiansong.github.io/homepage/index.html">Guoxian Song</a>,

				  <a href="https://seasonsh.github.io/">Yichun Shi</a>,

				<b>Di Chang</b>,

				  <a href="https://jingyangcarl.com">Jing Yang</a>,

				<a href="http://linjieluo.com/">Linjie Luo</a><br>

				<em>IEEE/ CVF Conference on Computer Vision and Pattern Recognition</em> (<i><b>CVPR</b></i>), 2024. <b style="color:red">(Highlight)</b>
		<p></p>
		<p>
			[<a href="https://freedomgu.github.io/DiffPortrait3D/" target="_blank">project page</a>]
			[<a href="https://arxiv.org/abs/2312.13016" target="_blank">paper</a>]
			[<a href="https://github.com/FreedomGu/DiffPortrait3D/" target="_blank">code</a>]
			[<a href="https://www.youtube.com/watch?v=mI8RJ_f3Csw" target="_blank">video</a>]
			<a class="more-link" href="https://github.com/FreedomGu/DiffPortrait3D" target="_blank"><img alt="GitHub stars" align="right"
				src="https://img.shields.io/github/stars/FreedomGu/DiffPortrait3D?style=social"></a>
		</p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>

    <tr>
		<td width="306">
		<img src="images/libre.jpg" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>LibreFace: An Open-Source Toolkit for Deep Facial Expression Analysis</b> <br>
			<br>
			<b>Di Chang</b>, <a href=https://yufengyin.github.io/ target=_blank rel=noopener>Yufeng Yin</a>, Zongjian Li, <a href="https://scholar.google.com/citations?user=HuuQRj4AAAAJ&hl=en" target=_blank rel=noopener>Minh Tran</a>, and <a href=https://people.ict.usc.edu/~soleymani/ target=_blank rel=noopener>Mohammad Soleymani</a><br>
		<em>IEEE/CVF Winter Conference on Applications of Computer Vision</em> (<i><b>WACV</b></i>), 2024.  <b>(Application Track)</b>
		<p></p>
		<p>
			[<a href="https://boese0601.github.io/libreface/" target="_blank">project page</a>]
			[<a href="https://arxiv.org/abs/2308.10713" target="_blank">paper</a>]
			[<a href="https://github.com/ihp-lab/LibreFace" target="_blank">code</a>]
			[<a href="" target="_blank">video</a>]
		</p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>


    <tr>
		<td width="306">
		<img src="images/rc.jpg" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>RC-MVSNet: Unsupervised Multi-View Stereo with Neural Rendering</b> <br>
			<br>
			<b>Di Chang</b>, <a href=https://aljazbozic.github.io/ target=_blank rel=noopener>Aljaž Božic</a>, <a href="https://people.epfl.ch/tong.zhang?lang=en" target=_blank rel=noopener>Tong Zhang</a>, Qingsong Yan, Yingcong Chen, <a href=https://people.epfl.ch/sabine.susstrunk target=_blank rel=noopener>Sabine Süsstrunk</a> and <a href=https://niessnerlab.org/ target=_blank rel=noopener>Matthias Nießner</a><br>
			<!-- <b>Di Chang</b>, <a>Aljaž Božič, Tong Zhang, Qingsong Yan, Yingcong Chen, Sabine Süsstrunk and Matthias Nießner <br> -->
		<em>European Conference on Computer Vision</em> (<i><b>ECCV</b></i>), 2022.
		<!-- <em>Arxiv Preprint</em> (<i><b>Under Review</b></i>), 2022. -->
		<p></p>
		<p>
			[<a href="https://boese0601.github.io/rc-mvsnet/" target="_blank">project page</a>]
			[<a href="https://arxiv.org/abs/2203.03949" target="_blank">paper</a>]
			[<a href="https://github.com/Boese0601/RC-MVSNet" target="_blank">code</a>]
			[<a href="https://www.youtube.com/watch?v=I_Q47TxTLbs" target="_blank">video</a>]
			<a class="more-link" href="https://github.com/Boese0601/RC-MVSNet" target="_blank"><img alt="GitHub stars" align="right"
				src="https://img.shields.io/github/stars/Boese0601/RC-MVSNet?style=social"></a>
		</p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>

    <!-- <tr>
		<td width="306">
		<img src="images/gbinet.JPG" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>Generalized Binary Search Network for Highly-Efficient Multi-View Stereo</b> <br>
			<br>
		<a href="https://mizhenxing.github.io/">Zhenxing Mi</a>, <b>Di Chang</b> and <a href="https://www.danxurgb.net/index.html">Dan Xu</a> <br>
		<em>IEEE/ CVF International Conference on Computer Vision and Pattern Recognition</em> (<i><b>CVPR</b></i>), 2022.
		<p></p>
		<p>
			[<a href="https://mizhenxing.github.io/gbinet/" target="_blank">project page</a>]
			[<a href="https://arxiv.org/abs/2112.02338" target="_blank">paper</a>]
            [<a href="https://github.com/MiZhenxing/GBi-Net" target="_blank">code</a>]
			<a class="more-link" href="https://github.com/MiZhenxing/GBi-Net" target="_blank"><img alt="GitHub stars" align="right"
				src="https://img.shields.io/github/stars/MiZhenxing/GBi-Net?style=social"></a>
		</p>

		<p><strong style="color:blue">Oral Presentation</strong></p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr> -->




</table>
<br>


<h2><a id="edu" ><font color="#CB4335">Education</font></a></h2>
<table>
	<tbody>
		<tr>
			<td width="800">
 
			<h4> University of Southern California, Los Angeles, USA <br>(Aug. 2022 - Present)</h4>
			<ul>
				<li>
				<b>Doctor of Philosophy in Computer Science</b></li>
				<li>Major Orientation: Deep Learning for 3D Vision and Affective Computing </li>
			</ul>
			</td>
<td>
	<img id="school_logo" src="./images/usc_cs_logo.jpeg" height="100px">
</td>
</tr>
<tr></tr>
</tbody></table>



<table>
	<tbody>
		<tr>
			<td width="800">
 
 <h4> Technical University of Munich, Munich, Germany (Aug. 2021 - Jul. 2022)</h4>
 <ul>
	<li>
	  <b>Bachelor of Science in Informatics</b></li>
	<li>Major Orientation: Deep Learning for 3D Perception, 3D Scanning and Spatial Learning </li>
	<li>Overall GPA: 1.2/1.0 </li>
	<li>Bachelor thesis: "Supervised and Unsupervised Multi View Stereo for Depth Inference"</li>
 </ul>
</td>
<td>
	<img id="school_logo" src="./images/TUM.jpg" height="100px">
</td>
</tr>
<tr></tr>
</tbody></table>

<table>
<tbody>
	<tr>
		<td width="800">
 <h4> Dalian University of Technology, Dalian, China (Sep. 2018 - Jul. 2021)</h4>
 <ul>
	<li>
	  <b>Bachelor of Engineering in Eletronic Information Engineering</b></li>
	<li>Major Orientation: Object Detection and Tracking</li>
	<li>Overall GPA: 91.5/100 | 3.93/4.0</li>
 </ul>
</td>
<td>
	<img id="school_logo" src="./images/DUT.jpg" height="100px">
</td>
</tr>
<tr></tr>
</tbody></table>


<h2><a id="C4" ><font color="#CB4335">Intern & Work Experience</font></a></h2>

<table>
	<tbody>
		<tr>
			<td width="800">
<h4>Meta, San Francisco, CA, USA (May. 2025 - Aug 2025) </h4>
	  <ul>
        <li>Position: Research Scientist Intern at Reality Lab and GenAI</li>
		  <li>Supervisor: Dr. <a  target="_blank" href=https://www.linkedin.com/in/stephanegrabli/ rel="external">Stephane Grabli</a>, 
			Dr. <a  target="_blank" href=https://aljazbozic.github.io/ rel="external">Aljaz Bozic</a>, and
			Dr. <a  target="_blank" href=https://sekunde.github.io/ rel="external">Ji Hou</a>
			
		</li>
        <li>Project:  Human Avatar Animation. </li>
    </ul>
</td>
<td>
	<img id="school_logo" src="./images/meta.jpg" height="100px">
</td>
</tr>
<tr></tr>
</tbody></table>

<table>
	<tbody>
		<tr>
			<td width="800">
<h4>TikTok, Los Angeles, CA, USA (Dec. 2024 - May. 2025) </h4>
	  <ul>
        <li>Position: Student Researcher at Seed Vision Research</li>
		  <li>Supervisor: Dr. <a  target="_blank" href=https://seasonsh.github.io/ rel="external"> Yichun Shi </a>,
			Dr. <a  target="_blank" href=https://pengwangucla.github.io/peng-wang.github.io/ rel="external"> Peng Wang </a>, and Dr. <a href="https://scholar.google.com/citations?user=78vU1IUAAAAJ&hl=en">Weilin Huang</a>
			
		</li>
        <li>Project:  Foundation Models for Text-guided Non-rigid Motion Editing </li>
    </ul>
</td>
<td>
	<img id="school_logo" src="./images/TikTok.jpeg" height="100px">
</td>
</tr>
<tr></tr>
</tbody></table>


<table>
	<tbody>
		<tr>
			<td width="800">
<h4>TikTok, San Jose, CA, USA (May. 2024 - Nov. 2024) </h4>
	  <ul>
        <li>Position: Research Scientist Intern at ByteDance Intelligent Creation Lab</li>
		  <li>Supervisor: Dr. <a  target="_blank" href=https://hongyixu37.github.io/homepage/ rel="external"> Hongyi Xu </a>,
			Dr. <a  target="_blank" href=https://seasonsh.github.io/ rel="external"> Yichun Shi </a>, 
			Dr. <a  target="_blank" href=https://guoxiansong.github.io/homepage/index.html rel="external"> Guoxian Song </a>, 
			and Dr. <a  target="_blank" href=http://linjieluo.com/ target="_blank" rel="external">Linjie Luo</a>
			
		</li>
        <li>Project: Dynamic Human Video Generation with Diffusion Models</li>
    </ul>
</td>
<td>
	<img id="school_logo" src="./images/TikTok.jpeg" height="100px">
</td>
</tr>
<tr></tr>
</tbody></table>



<table>
	<tbody>
		<tr>
			<td width="800">
<h4>TikTok, San Jose, CA, USA (May. 2023 - Nov. 2023) </h4>
	  <ul>
        <li>Position: Research Scientist Intern at ByteDance Intelligent Creation Lab</li>
		<li>Supervisor: Dr. <a  target="_blank" href=https://seasonsh.github.io/ rel="external"> Yichun Shi </a>, Dr. <a  target="_blank" href=https://guoxiansong.github.io/homepage/index.html rel="external"> Guoxian Song </a>, Dr. <a  target="_blank" href=https://hongyixu37.github.io/homepage/ rel="external"> Hongyi Xu </a>, and Dr. <a  target="_blank" href=https://scholar.google.com/citations?user=_MAKSLkAAAAJ&hl=en target="_blank" rel="external">Xiao Yang</a></li>
        <li>Project: Human Video Animation with Diffusion Models </li>
    </ul>
</td>
<td>
	<img id="school_logo" src="./images/TikTok.jpeg" height="100px">
</td>
</tr>
<tr></tr>
</tbody></table>

<table>
	<tbody>
		<tr>
			<td width="800">
<h4>EPFL, Lausanne, Switzerland (Jul. 2022 - Oct. 2022) </h4>
	  <ul>
        <li>Position: Summer@EPFL (Top 2% from the candidates in the world) hired by <a  target="_blank" href=https://www.epfl.ch/labs/ivrl/ target="_blank" rel="external">IVRL</a></li>
		  <li>Supervisor: Dr. <a  target="_blank" href=https://sites.google.com/view/tong-zhang rel="external"> Tong Zhang </a>
			and Prof. <a  target="_blank" href=https://people.epfl.ch/sabine.susstrunk?lang=en target="_blank" rel="external"> Sabine Süsstrunk</a></li>
        <li>Project: Video Synthesis with Diffusion Models </li>
    </ul>
</td>
<td>
	<img id="school_logo" src="./images/EPFL.png" height="100px">
</td>
</tr>
<tr></tr>
</tbody></table>

<!-- <table>
	<tbody>
		<tr>
			<td width="800"> 
      <h4> TUM, Munich, Bayern, Germany  (Mar. 2022 - Aug. 2022) </h4>
	  <ul>
        <li>Position: Guided Research in <a  target="_blank" href=https://www.3dunderstanding.org target="_blank" rel="external">3D AI Group</a></li>
        <li>Supervisor: Prof. <a  target="_blank" href=https://www.3dunderstanding.org/team.html target="_blank" rel="external"> Angela Dai </a></li>
        <li>Project: Single-View Reconstruction and Category-level NeRF</li>
    </ul>
</td>
<td>
	<img id="school_logo" src="./images/TUM.jpg" height="100px">
</td>
</tr>
<tr></tr>
</tbody></table> -->

<!--    <img id="school_logo" src="./pics/Flexiv.png">-->
          <!--<h4> The University of North Carolina at Chapel Hill, NC, USA  & <br> Shanghai United ImagingIntelligence Co., Ltd, China  (Jun. 2018 - Nov. 2018)</br> </h4>-->
		  <table>
			<tbody>
				<tr>
					<td width="800"> 
		  <h4> TUM, Munich, Bayern, Germany  (Aug. 2021 - Mar. 2022) </h4>
          <ul>
            <li>Position: Research Praktikum in <a  target="_blank" href="https://www.niessnerlab.org/" target="_blank" rel="external">Visual Computing Group</a></li>
            <li>Supervisor: Prof.<a  target="_blank" href=https://www.niessnerlab.org/members/matthias_niessner/profile.html target="_blank" rel="external"> Matthias Niessner</a> and
				M.Sc <a  target="_blank" href=https://aljazbozic.github.io/ target="_blank" rel="external"> Aljaž Božič </a>
			</li>
            <li>Project: Unsupervised Multi-View Stereo </li>
            <!-- <br/>
            <br/> -->
            <!-- <td width="306">
            <img src="pics/masage.gif" width="285px" height= "180px" style="box-shadow: 4px 4px 8px #888">
            </td> -->
      </ul>
	</td>
	<td>
		<img id="school_logo" src="./images/TUM.jpg" height="100px">
	</td>
	</tr>
	<tr></tr>
	</tbody></table>
<!--    <img id="school_logo" src="./pics/uII.png">-->
<table>
	<tbody>
		<tr>
			<td width="800">
      <h4> HKUST, Hong Kong, China  (Mar. 2021 - Sep. 2021) </h4>
	  <ul>
        <li>Position: Research Intern in <a  target="_blank" href="https://www.danxurgb.net/index.html" target="_blank" rel="external">HKUST Vision Group (MM-Lab at HKUST)</a></li>
        <li>Supervisor: Prof.<a  target="_blank" href=https://www.danxurgb.net/index.html target="_blank" rel="external"> Dan Xu</a>
        and M.Sc <a  target="_blank" href=https://mizhenxing.github.io/ target="_blank" rel="external"> Zhenxing Mi </a></li>
        <li>Project: Multi View Stereo Depth Estimation </li>
    </ul>
</td>
<td>
	<img id="school_logo" src="./images/HKUST.jpg" height="100px">
</td>
</tr>
<tr></tr>

</tbody></table>


<h2><font color="#CB4335">Students</font></h2>
      <ul>
		<li>
			<a  target="_blank" href=https://www.linkedin.com/in/jessica-fu-60a504254/ target="_blank" rel="external">Jessica Fu</a>. (Undergraduate student at USC, recruited through CURVE Fellowship. 2023 Fall, 2024 Spring)</li>		  
		<li>
			<a  target="_blank" href=https://www.linkedin.com/in/kevin-hopkins-1471781ba/ target="_blank" rel="external">Kevin Hopkins</a>. (Master student at USC. 2023 Fall, 2024 Spring)</li>
		<li>
			<a  target="_blank" href=https://www.linkedin.com/in/elliexing/ target="_blank" rel="external">Ellie Xing</a>. (Undergraduate student at USC, recruited through CURVE Fellowship. 2024 Spring)</li>
		<li>
			<a  target="_blank" href=https://www.linkedin.com/in/hongkun-kevin-gong-7296a8262/ target="_blank" rel="external">Hongkun Gong</a>. (Undergraduate student at USC. 2024 Spring)</li>
      </ul>

<br>

<!-- <h2><font color="#CB4335">Honors and Awards</font></h2>
      <ul> -->
		<!-- <li>
			Mar 2022 <b>Outstanding UG graduates</b> of DUT </li>      
		<li>
			Oct 2021 <b>Outstanding Undergraduate</b> of DUT </li>     
        <li>
          May 2021 <b>The Third prize</b> 2021 China Underwater Robot Professional Contest - Acoustics Track </li>
		<li>
          May 2021 <b>The Second prize</b> 2021 China Underwater Robot Professional Contest - Optics Track </li>
		<li>
			Oct 2020 <b>Outstanding Undergraduate</b> of DUT </li>     
		<li>
			Oct 2019 <b>Outstanding Undergraduate</b> of DUT </li>        
      </ul> -->

<!-- <br> -->

<h2><font color="#CB4335">Academic Service</font></h2>
Reviewer of the following conferences:
<br>
<br>
ECCV 2022, 2024<br>
NeurIPS 2022, 2024, 2025<br>
CVPR 2024, 2025<br>
ICLR 2025<br>
ICML 2025<br>
ICCV 2025<br>


<br>


<h2><font color="#CB4335">Teaching</font></h2>
      <ul>
		<li>
			Graduate Teaching Assistant, CSCI 103 Introduction to Programming - 2022 Fall</li>
		<li>
			Graduate Teaching Assistant, CSCI 535 Multimodal Probabilistic Learning of Human Communication - 2024 Spring</li>
        <!-- <li>
          Sep 2017 <b>National Scholarship(Graduate)</b>, (highest honor for graduates) <strong style="color:blue">top 1% nationwide</strong></li>
        <li>
          Sep 2015 <b>National Scholarship(Undergraduate)</b>, (highest honor for undergraduates, top 2% nationwide) </li>
		<li>
          May 2018 <b>KaiYuan Motivational Scholarship</b> <strong style="color:blue">top 0.5% in Shanghai Jiao Tong University</strong></li>
        <li>
          Sep 2015 <b>Presidential Scholarship</b>, (highest honor in Shandong University) <strong style="color:blue">top 0.2% in Shan Dong University</strong></li>
        <li>
          Sep 2015 <b>BaoGang Excellent student Scholarship</b>, (4 Places per year at Shandong University) </li>
		<li>
          Sep 2015 &amp; Sep 2014 &amp; Sep 2015</b> <b>First Prize Scholarship</b> (Top 6% in China,three-year continuous)</li> -->
      </ul>

<br>

<h2><font color="#CB4335">Miscellaneous</font></h2>
      <ul>
		<li>
			(8 yrs +) 🎮Video Games, I am a lover of League of Legends, highest rank: Platinum II of EU server S12.</li>
		<li>
			(2 yr +) 🏁Racing, I love racing with my Chevy Camaro SS (It's an aftermarket upgraded V8!). I've been to Sonoma Raceway, Laguna Seca Raceway, Buttton Willow Raceway in California, USA and Nürburgring Nordschleife Track in Rhineland-Palatinate, Germany.  &nbsp&nbsp My Camaro 👇 :D </li>
      </ul>

<div style="text-align: center;">
    <img src="./images/Camaro.jpg" alt="Camaro SS" style="width: 100%; max-width: 600px;">
</div>
<br>




<div id="footer1">
	<h2> </h2>
		<div align="center">
		  <small>This page has been visited for
			<a href="https://www.easycounter.com/">
			<img src="https://www.easycounter.com/counter.php?dichang" border="0" alt="HTML Hit Counter"></a>times</small>
		  </div> 
	</div>
  <p>
	<center>
	<div align="center" style="width:20%">
	  <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=grr8tSJTdsbdU-vHO6Of-5W7jpLTZvSVYTu6BUgf02M"></script>
	</div>        
	</center>
  </p>
  

<p align="center"><font color="#999999">Last update: May. 21, 2025</font></p>



</body>

</html>
